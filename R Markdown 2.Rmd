---
title: "Assigment_2"
author: "The Winners"
date: '2022-06-13'
output: html_document
---

TITLE: Assigment_2 


```{r 0}
# PRELIMINARY OPERATIONS

# Clear the variables
rm(list = ls())


# Set the working directory to source file location with
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))


# Install packages
packages <- c("tidyverse", "rsdmx", "eurostat", "tbl2xts",
              "tidyquant", "BCDating", "pwt10", "dplyr",
              "stargazer", "car", "forecast", "tseries",
              "quantmod", "eurostat", "stargazer",
              "skedastic","Metrics","mFilter", "aTSA","lmtest","xts")
new.packages <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(new.packages)) install.packages(new.packages)
invisible(lapply(packages, library, character.only = TRUE))

# Load packages
library(quantmod)
library(eurostat)


```

## Q1: Data Generating Process

We simulate an AR(i), a MA(i) and an ARMA(i,j) study the correlogram, where we choose i and j as positive integers, while the parameters can be positive or negative.

```{r 1a}
set.seed(1111)
```

We define functions:
- to generate a general ARMA time series of order i,j so that it could be also an AR or an MA
- to fit the ARMA function
- to plot the different correlations

```{r 2a}
arma=function(ar,ma){
  armats <- arima.sim(model=list(ar=ar,ma=ma), n=1000)
  armats
  return(armats)
}

armafit=function(armats,order){
  armatsfit = arima(armats, order, include.mean = FALSE)
  return(armatsfit)
}

plotcorr=function(ts,main){
  plot(ts, type="l", main=main)
  acf(ts, main=main)
  pacf(ts, main=main)
}
```

# INTERPRETATION 1 

We simulate four AR(1): two with positive parameters and the other two with negative parameters

```{r 3a}
#Simulate an AR(1) with a positive parameter
ar=c(0.3)
ma=c(0)
order=c(1,0,0)
arts1=arma(ar,ma)
artsfit1 = armafit(arts1, order)
stargazer(artsfit1, type="text")
plotcorr(arts1,main="AR(1)pos.a")

#Simulate an AR(1) with a positive parameter
ar=c(0.5)
ma=c(0)
order=c(1,0,0)
arts2=arma(ar,ma)
artsfit2 = armafit(arts2, order)
stargazer(artsfit2, type="text")
plotcorr(arts2,main="AR(1)pos.b")

#Simulate an AR(1) with a negative parameter
ar=c(-0.3)
ma=c(0)
order=c(1,0,0)
arts3=arma(ar,ma)
artsfit3 = armafit(arts3, order)
stargazer(artsfit3, type="text")
plotcorr(arts3,main="AR(1)neg.a")

#Simulate an AR(1) with a negative parameter
ar=c(-0.5)
ma=c(0)
order=c(1,0,0)
arts4=arma(ar,ma)
artsfit4 = armafit(arts4, order)
stargazer(artsfit4, type="text")
plotcorr(arts4,main="AR(1)neg.b")
```

We simulate four MA(1): two with positive parameters and the other two with negative parameters

```{r 4a}
#Simulate an MA(1) with a positive parameter
ar=c(0)
ma=c(0.2)
order=c(0,0,1)
mats1=arma(ar,ma)
matsfit1 = armafit(mats1, order)
stargazer(matsfit1, type="text")
plotcorr(mats1,main="MA(1)pos.a")

#Simulate an MA(1) with a positive parameter
ar=c(0)
ma=c(0.3)
order=c(0,0,1)
mats2=arma(ar,ma)
matsfit2 = armafit(mats2, order)
stargazer(matsfit2, type="text")
plotcorr(mats2,main="MA(1)pos.b")

#Simulate an MA(1) with a negative parameter
ar=c(0)
ma=c(-0.2)
order=c(0,0,1)
mats3=arma(ar,ma)
matsfit3 = armafit(mats3, order)
stargazer(matsfit3, type="text")
plotcorr(mats3,main="MA(1)neg.a")

#Simulate an MA(1) with a negative parameter
ar=c(0)
ma=c(-0.3)
order=c(0,0,1)
mats4=arma(ar,ma)
matsfit4 = armafit(mats4, order)
stargazer(matsfit4, type="text")
plotcorr(mats4,main="MA(1)neg.b")
```

After simulating AR(1) and MA(1), we simulate one ARMA(1,1) and one ARMA(2,2).

```{r 5a}
# Simulate an ARMA(1,1) with certain parameters
ar=c(0.999999)
ma=c(0.5)
order=c(1,0,1)
armats1=arma(ar,ma)
armatsfit1 = armafit(armats1, order)
stargazer(armatsfit1, type="text")
plotcorr(armats1,main="ARMA(1,1)")

# Simulate an ARMA(2,2) with certain parameters
ar=c(0.3,-0.5)
ma=c(-0.2, 0.2)
order=c(2,0,2)
armats2=arma(ar,ma)
armatsfit2 = armafit(armats2, order)
stargazer(armatsfit2, type="text")
plotcorr(armats2,main="ARMA(2,2)")
```

# INTERPRETATION 2

We simulate two AR():
1. AR(4)  with two positive parameters and two with negative parameters
2. AR(6) with three positive parameters and three with negative parameters

```{r 6a}
#Simulate an AR(4) with certain parameters
ar=c(0.3,0.25,-0.22,-0.15)
ma=c(0)
order=c(4,0,0)
arts1=arma(ar,ma)
artsfit1 = armafit(arts1, order)
stargazer(artsfit1, type="text")
plotcorr(arts1,main="AR(4)")

# Simulate an AR(6) with certain parameters
ar=c(0.35,0.33,0.3,-0.18, -0.15, -0.1)
ma=c(0)
order=c(6,0,0)
arts2=arma(ar,ma)
artsfit2 = armafit(arts2, order)
stargazer(artsfit2, type="text")
plotcorr(arts2,main="AR(6)")
```

We simulate two MA(): 
1. MA(4) with two positive parameters and two negative parameters
2. MA(6) with three positive parameters and three negative parameters

```{r 7a}
# Simulate an MA(4) with certain parameters
ar=c(0)
ma=c(0.2,0.2,-0.2,-0.2)
order=c(0,0,4)
mats1=arma(ar,ma)
matsfit1 = armafit(mats1, order)
stargazer(matsfit1, type="text")
plotcorr(mats1,main="MA(4)")

# Simulate an MA(6) with certain parameters
ar=c(0)
ma=c(0.2,0.2,0.2,-0.2,-0.2,-0.2)
order=c(0,0,6)
mats2=arma(ar,ma)
matsfit2 = armafit(mats2, order)
stargazer(matsfit2, type="text")
plotcorr(mats2,main="MA(6)")
```

After simulating AR() and MA(), we simulate one ARMA(3,1) and one ARMA(1,3).

```{r 8a}

# Simulate an ARMA(3,1) with certain parameters
ar=c(0.2,0.2,-0.2)
ma=c(-0.2)
order=c(3,0,1)
armats1=arma(ar,ma)
armatsfit1 = armafit(armats1, order)
stargazer(armatsfit1, type="text")
plotcorr(armats1,main="ARMA(3,1)")

# Simulate an ARMA(1,3) with certain parameters
ar=c(0.1)
ma=c(0.1,-0.1,-0.1)
order=c(1,0,3)
armats2=arma(ar,ma)
armatsfit2 = armafit(armats2, order)
stargazer(armatsfit2, type="text")
plotcorr(armats2,main="ARMA(1,3)")

```


## Q2: Forecasting Comparison

We decided to simulate an ARMA(2,1) as a baseline time series 
```{r 9a}
# Simulating an arma(2,1) as a baseline time series
ar=c(0.43,0.37)
ma=c(0.6)
order=c(2,0,1)
armatsnew=arma(ar,ma)
acf(armatsnew)
```

And then we divide our sample time series in two parts: the train set for estimation and the test set to forecast
```{r 10a}
n=length(armatsnew)/2
armatstrain=armatsnew[1:n]
armatstest=armatsnew[(n+1):length(armatsnew)]
```

After that, we fit AR(1), ARMA(2,1), naive forecast, mean forecast on the train set to obtain parameters to predict. On this predictive we calculate the errors using MAE and RMSE to compare values. 

```{r 11.a}

#Model fitting with an AR(1), 
order=c(1,0,0)
arfit=armafit(armatstrain,order)
plot(arfit$coef)
summary(arfit)
arfitpred=predict(arfit,n.ahead=500, interval="confidence")
maear=mae(armatstest,arfitpred$pred)
rmsear=rmse(armatstest,arfitpred$pred)
cbind(maear,rmsear)

#Model fitting with ARMA(2,1)
order=c(2,0,1)
armafitting=armafit(armatstrain,order)
plot(armafitting$coef)
summary(armafitting)
armafitpred=predict(armafitting,n.ahead=500, interval="confidence")
maearma=mae(armatstest,armafitpred$pred)
rmsearma=rmse(armatstest,armafitpred$pred)
cbind(maearma,rmsearma)


#Model fitting with naive forecast
naivefit=naive(armatstest, h=500)
plot(naivefit)
naivefitpred=predict(naivefit,n.ahead=500, interval="confidence")
maenaive=mae(armatstest,naivefitpred$fitted[-c(1)])
rmsenaive=rmse(armatstest,naivefitpred$fitted[-c(1)])
cbind(maenaive,rmsenaive)

#Model fitting with mean forecast
meanfit=lm(armatstrain ~ 1)
plot(c(armatstrain,meanfit$fitted.values))
meanfitpred=predict(meanfit,n.ahead=500, interval="confidence")
maemean=mae(armatstest,meanfit[["coefficients"]])
rmsemean=rmse(armatstest,meanfit[["coefficients"]])
cbind(maemean,rmsemean)

```


## Q3: Nelson Plosser data
```{r 3aa, echo=FALSE}
# load package:
library(prediction)
```


We download the same series (data of Nelson Plosser) from FRED website and we decide to transform the data in log level
```{r 3b}
nipa <- c(
    "GNP", "GNPC96", "GNPGDPUSA156NUPN",
    "INDPRO", "CE16OV", "UNRATE", "A001RI1Q225SBEA",
    "FPCPITOTLZGUSA", "CES0500000003", "M2REAL", "M2V",
    "DAAA", "M1125AUSM343NNBR"
)
for (i in 1:length(nipa)) {
    getSymbols(nipa[i], src = "FRED")
}

# Take the LOG
GNP <- log(GNP)
GNPC96 <- log(GNPC96) # Real GNP at cosntant price level 1996
GNP_GDP_ratio <- log(GNPGDPUSA156NUPN)
INDPRO <- log(INDPRO) # industrial production
emp <- log(CE16OV) # Employment in industry
unemp <- log(UNRATE) # Unemployment rate
GNP_defletor <- log(A001RI1Q225SBEA) # GNP deflator
cons_prices <- log(FPCPITOTLZGUSA) # Consumer prices
wages <- log(CES0500000003) # avg hourly wage private sector
real_wages <- log((CES0500000003 / A001RI1Q225SBEA) * 100) # real wages
Money_stock <- log(M2REAL) # Money stock
Velocity <- log(M2V) # Velocity of money
bond_yield <- DAAA # Bond yield
common_stock_prices <- log(M1125AUSM343NNBR) # Common stock prices
```

We create a Random walk time series with drift
```{r 3c}

generateRandomWalk <- function(sim.num) {
   
    GNP_sim_rw_drift <- arima.sim(
        n = sim.num,
        model = list(order = c(0, 0, 0)), mean = 0.9
    )
    
# Use the command cumsum to convert GNP_sim to a RW
    GNP_sim_rw_drift_rw <- cumsum(GNP_sim_rw_drift)
    return(GNP_sim_rw_drift_rw)
}
GNP_sim_rw_drift_rw <- generateRandomWalk(1000)
```

To simplify the procedures we create a dataframe with the data
```{r 3d}

data <- list(
    GNP, GNPC96, GNP_GDP_ratio, INDPRO, emp, unemp,
    GNP_defletor, cons_prices, wages, real_wages,
    Money_stock, Velocity, bond_yield, common_stock_prices,
    GNP_sim_rw_drift_rw)

# and we substitute the NA values in each elements of the data with the 0

for (i in 1:length(data)) {
    for (j in 1:length(data[[i]])) {
        if (!is.finite(data[[i]][j])) {
            data[[i]][j] <- 0
        }
    }
}
```

Now we need a function that compute the standard deviation of each element in the data
```{r 3e}

stdError <- function(data, i) {
    return(sqrt(var(data[[i]])))
}

# we compute the autocorrelation function of the data using acf() and we assigned names to the rows of the matrix using the names of the elements in the vector

generateTable <- function(data) {
    acf_list <- matrix(NA, nrow = length(data), ncol = 9)

    label <- c(
        "GNP", "Real GNP", "GNP GDP ratio", "Industrial Production", "Employment",
        "Unemployment rate", "GNP deflator", "Consumer prices", "Wages", "Real wages",
        "Money stock", "Velocity", "Bond yield", "Common stock prices",
        "Random walk with drift"
    )

    col.label <- c("Period", "T", "r1", "r2", "r3", "r4", "r5", "r6", "sd")
    for (i in 1:length(data)) {
        acf_list[i, 1] <- paste(min(index(data[[i]])), max(index(data[[i]])), sep = " <-> ") # period
        acf_list[i, 2] <- length(data[[i]]) # sample size
        acf_list[i, 3:(ncol(acf_list) - 1)] <- round(acf(data[[i]], lag.max = 6, plot = FALSE)$acf[-1], 3) # autocorrelation function
        acf_list[i, ncol(acf_list)] <- round(stdError(data, i), 3) # standard error
    }
    colnames(acf_list) <- col.label
    rownames(acf_list) <- label
    return(acf_list)
}

```

We generate the Table 1: Sample autocorrelation of the data
```{r 3f}
acf_autcorr <- generateTable(data)
View(acf_autcorr)
```

Then we generate data using the first difference of the data, and we take the first difference of each element of the data and list of the first differences with the same length as the original data

```{r 3g}

firstDiff <- function(data) {
    first_diff <- list()
    for (i in 1:(length(data))) {
        first_diff[[i]] <- diff(data[[i]], lag = 1)
        
# replace the NA values in each element of the data with 0
        for (j in 1:length(data[[i]])) {
            if (!is.finite(data[[i]][j])) {
                first_diff[[i]][j] <- 0
            }
        }
    }

 # replace the first element in each element of the first_diff with 0
    for (i in 1:length(first_diff)) {
        first_diff[[i]][1] <- 0
    }
    return(first_diff)
}

# recall the function to compute the first difference of the data
first_diff <- firstDiff(data)
```

Then we generate the Table2:  the autocorrelation of the first difference of the data
```{r 3h}
acf_autcorr_diff <- generateTable(first_diff)
View(acf_autcorr_diff)
```

After, we need to define a function AIC_score to compute the AIC on the fitted model
```{r 3i}
AIC_score <- function(resid) {

    AIC_score <- log(length(resid)) + 2 * length(resid)
    return(AIC_score)
}
```

And another function that works in this way: given the first difference of the data,select the best ARIMA model for each element of the data with AIC, detrend each element of data with the fitted model of the best ARIMA model, compute the residuals of the data from the fitted model, compute the sample autocorrelation of the residuals, return the sample autocorrelation of the residuals for each element of the data

```{r 3l}
theUltimateFunction <- function(first_diff) {
# define a matrix containing the iper-parameters for the best ARIMA model (with min AIC)
    iper_param <- matrix(NA, nrow = length(first_diff), ncol = 3)
    
  # define the vector containing the all possible hyperparameters
    p <- c(0:3)
    d <- c(0:3)
    q <- c(0:3)
   
# create a matrix containing all possible combinations of the hyperparameters
    iper_param_matrix <- matrix(NA,
        nrow = (length(p) * length(d) * length(q)),
        ncol = 3)

# create a vector containing the sample autocorrelation of the residuals for each element of the data
    acf_residuals <- list()


# fill the matrix with the possible combinations of the hyperparameters
    count <- 1
    for (i in 1:length(p)) {
        for (j in 1:length(d)) {
            for (k in 1:length(q)) {
                iper_param_matrix[count, ] <- c(p[i], d[j], q[k])
                count <- count + 1
            }
        }
    }

```


Now we fit the ARIMA model to each element of the data with 80% of the elements of the data as training data
```{r 3m}
for (i in 1:length(first_diff)) {
        resid_vector <- c()
 # vector containing the sample autocorrelation of the residuals
        acf_vector <- list()
  # AIC vector containing the AIC of the fitted model
        AIC_vector <- c()
# vector containing the sum of AIC residuals of the fitted model
        sum_acf_residuals <- c()


# we define the vector containing the 80% of the elements of the data
        timeserie <- as.vector(first_diff[[i]])
        train_data <- timeserie[1:(length(timeserie) * 0.8)]

# we transform train_data into a time series
        train_data <- ts(as.vector(train_data))

# we define the vector containing the 20% of the elements of the data
        test_data <- timeserie[(length(timeserie) * 0.8) +
            1:length(timeserie)]

# we transform test_data into a time series
        test_data <- ts(test_data)

```

    
Another point is to fit the ARIMA model to the training data with all possible combinations of the hiperparameters given by the matrix iper_param_matrix
```{r 3n}
for (j in 1:nrow(iper_param_matrix)) {
            check <- FALSE
            print(paste("object:", i, "iper:", j, sep = " "))
# define the vector containing the iper-parameters
            iper_param_vector <- iper_param_matrix[j, ]
# try if the ARIMA will work (convergence problem) otherwise pass
            check <- tryCatch(
                {
# fit the ARIMA model
                    fitted_model <- arima(train_data,
                        order = iper_param_vector, method = "ML" )
# prediction of the fitted model on the test data
                    predicted <- forecast(model = fitted_model, object = test_data)
                },
                error = function(e) {
# if the ARIMA model does not work, pass

                    return(TRUE)
                },
                warning = function(cond) {
# if the ARIMA model does not work, pass

                    return(TRUE)
                }
            )
            if (class(check) != "logical") {
                fitted_model <- arima(train_data,
                    order = iper_param_vector, method = "ML"
                )
# prediction of the fitted model on the test data
                predicted <- forecast(model = fitted_model, object = test_data)

# store the residual in the list resid_vector only if the prediction residuals is not NA
                resid_vector <- c()
                for (z in 1:length(predicted$residuals)) {
                    if (is.finite(predicted$residuals[z])) {
                        resid_vector <- c(
                            resid_vector,
                            as.double(predicted$residuals[z])
                        )
                    }
                }

```

        
Now we extract the AIC of the fitted model
```{r 3o}
   AIC_vector <- c(AIC_vector, AIC_score(resid_vector))

 # tranform the residuals into a time series
                resid_ts <- c()
                for (item in 6:length(resid_vector)) {
                    resid_ts <- c(resid_ts, resid_vector[[item]][1])
                }
                resid_ts <- ts(resid_ts)
# compute the sample autocorrelation of the residuals
                acf_vector[[j]] <- c(acf(resid_ts,
                    lag.max = 6,
                    plot = FALSE
                )$acf)
# sum the sample autocorrelation of the residuals
                sum_acf_residuals <- c(sum_acf_residuals, sum(abs(acf_vector[[j]])))
            } else {
                print("ARIMA model does not work")
            }
        }
```

             
Now we select the best ARIMA model for each element of the data with AIC, we define the vector containing the AIC of the best ARIMA model for each element of the data

Then we define the index of the best ARIMA model which minimizes the sum of the sample autocorrelation of the residuals
```{r 3p}
        index_min <- which.min(sum_acf_residuals)
        print(paste("best index:", index_min, "value:", AIC_vector[index_min], sep = " "))
# define the vector containing the iper-parameters of the best  ARIMA model for each element of the data
        iper_param[i, ] <- iper_param_matrix[index_min, ]

# define a vector containing the sample autocorrelation of the residuals of the best ARIMA model for each element of the data
        acf_residuals[[i]] <- acf_vector[[index_min]]
    }
    output <- matrix(NA, nrow = length(first_diff), ncol = 9)
    for (i in 1:length(first_diff)) {
        output[i, ] <- c(
            iper_param[i, ][1],
            iper_param[i, ][2],
            iper_param[i, ][3],
            acf_residuals[[i]][1],
            acf_residuals[[i]][2],
            acf_residuals[[i]][3],
            acf_residuals[[i]][4],
            acf_residuals[[i]][5],
            acf_residuals[[i]][6]
        )
    }
```


 We give the row names to the output matrix
```{r 3q}

    rownames(output) <- c(
        "GNP", "Real GNP", "GNP GDP ratio", "Industrial Production", "Employment",
        "Unemployment rate", "GNP deflator", "Consumer prices", "Wages", "Real wages",
        "Money stock", "Velocity", "Bond yield", "Common stock prices",
        "Random walk with drift"
    )

 # give the column names to the output matrix
    colnames(output) <- c("AR(p)", "MA(d)", "MA(q)", "t1", "t2", "t3", "t4", "t5", "t6")

    return(output)
}



```

Finally we generate Table 3: the sample autocorrelation of the residuals of the best ARIMA model
```{r 3r}
theUltimateOutput <- theUltimateFunction(first_diff)
View(theUltimateOutput)
```


Now we need to perform augmented Dickey-Fuller test  on the first_diff data to check if the data is stationary and define the vector containing the results of the Augmented Dickey-Fuller test for each element of the data
```{r 3s}
adfTest <- function(data) {
    test_results <- c()
    for (i in 1:length(data)) {
        test_results <- c(test_results, adf.test(data[[i]])$p.value)
    }
```


In conclusion we generate Table 4: the results of the Augmented Dickey-Fuller test
```{r 3t}
   
    return(test_results)
}

# call the function to perform the Augmented Dickey-Fuller test
adf_results <- adfTest(first_diff)
alpha <- 0.05

# if the data is stationary, the Augmented Dickey-Fuller test will return a p-value less than alpha, otherwise the data is non-stationary
adf_stationry_results <- c()
for (i in 1:length(adf_results)) {
    if (adf_results[i] < alpha) {
        adf_stationry_results <- c(adf_stationry_results, "Stationary")
    } else {
        adf_stationry_results <- c(adf_stationry_results, "Non-stationary")
    }
}
adf_matrix_output <- matrix(NA, nrow = length(first_diff), ncol = 2)
for (i in 1:length(first_diff)) {
    adf_matrix_output[i, ] <- c(adf_results[i], adf_stationry_results[[i]])
}
```
 
Now we give the row names to the output matrix
```{r 3v}
rownames(adf_matrix_output) <- c(
    "GNP", "Real GNP", "GNP GDP ratio", "Industrial Production", "Employment",
    "Unemployment rate", "GNP deflator", "Consumer prices", "Wages", "Real wages",
    "Money stock", "Velocity", "Bond yield", "Common stock prices",
    "Random walk with drift")

# give the column names to the output matrix
colnames(adf_matrix_output) <- c("p-value", "Stationary or Non-stationary")
View(adf_matrix_output)
```




